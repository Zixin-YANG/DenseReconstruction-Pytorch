# parser.add_argument('--adjacent_range', nargs='+', type=int, required=True,
#                     help='frame interval range for sampling two frames')
# parser.add_argument('--image_downsampling', type=float, default=4.0,
#                     help='image downsampling rate to speed up training and reduce overfitting')
# parser.add_argument('--network_downsampling', type=int, default=64,
#                     help='network downsampling rate from input to bottleneck layer')
# parser.add_argument('--input_size', nargs='+', type=int, default=None,
#                     help='input size for architecture summary')
# parser.add_argument('--batch_size', type=int, default=8, help='batch size for training and testing')
# parser.add_argument('--num_workers', type=int, default=8, help='number of workers for data loader')
# parser.add_argument('--slp_weight', type=float, default=1.0, help='weight for sparse log prob loss')
# parser.add_argument('--dcl_weight', type=float, default=0.5, help='weight for depth consistency loss')
# parser.add_argument('--sfl_weight', type=float, default=100.0, help='weight for sparse flow loss')
# parser.add_argument('--dl_weight', type=float, default=20.0, help='weight for descriptor loss')
# parser.add_argument('--lr_range', nargs='+', type=float, default=[1.0e-4, 1.0e-3],
#                     help='cyclic lr range (min, max)')
# parser.add_argument('--inlier_percentage', type=float, default=0.998,
#                     help='percentage of inliers of SfM point clouds (to prune some outliers)')
# parser.add_argument('--display_interval', type=int, default=50, help='iteration interval for image display')
# parser.add_argument('--save_interval', type=int, default=2, help='interval for saving model')
# parser.add_argument('--visible_interval', type=int, default=5,
#                     help='range for propagating point visibility information')
# parser.add_argument('--training_patient_id', nargs='+', type=int, required=True, help='id of the training patients')
# parser.add_argument('--load_intermediate_data', action='store_true',
#                     help='whether or not to load pre-compute data')
# parser.add_argument('--load_trained_model', action='store_true',
#                     help='whether to load pre-trained model')
# parser.add_argument('--trained_model_path', type=str, required=True, help='path to the trained model')
# parser.add_argument('--num_epoch', type=int, required=True, help='number of epochs in total')
# parser.add_argument('--architecture_summary', action='store_true', help='summarize the network architecture')
# parser.add_argument('--data_root', type=str, required=True, help='path to the training data')
# parser.add_argument('--log_root', type=str, required=True, help='root of the training logs')
# parser.add_argument('--precompute_root', type=str, required=True, help='root of the pre-compute data')
# parser.add_argument('--num_iter', type=int, default=1000,
#                     help='number of iterations per epoch')
# parser.add_argument('--descriptor_model_path', type=str, required=True,
#                     help='path to the trained feature matching model')

--adjacent_range
5
30
--image_downsampling
4.0
--network_downsampling
64
--input_size
256
320
--batch_size
1
--num_workers
1
--slp_weight
1.0
--dcl_weight
0.5
--sfl_weight
1.0
--dl_weight
0.1
--lr_range
1.0e-4
1.0e-3
--inlier_percentage
0.9
--display_interval
20
--visible_interval
5
--save_interval
1
--training_patient_id
1
--num_epoch
200
--architecture_summary
--data_root
"D:\Data\example_training_data_root\example_training_data_root"
--log_root
"D:\Data\example_training_data_root\Train"
--precompute_root
"D:\Data\example_training_data_root\Train\precompute"
--descriptor_model_path
"D:\Data\trained_models\descriptor\checkpoint_model_epoch_48_0.5595721672900287_0.6460666084922773_0.7442676028192171.pt"
--load_trained_model
--trained_model_path
"D:\Data\example_training_data_root\Train\depth_train_6_24_21_36\checkpoint_model_epoch_6_1.365839961006886_0.0_0.0_0.33186495108554365_1.0339750069489326.pt"


# Trial 2
--adjacent_range
5
30
--image_downsampling
4.0
--network_downsampling
64
--input_size
256
320
--batch_size
1
--num_workers
1
--slp_weight
0.05
--dcl_weight
0.5
--sfl_weight
10.0
--dl_weight
0.0
--lr_range
1.0e-4
1.0e-3
--inlier_percentage
0.9
--display_interval
20
--visible_interval
5
--save_interval
1
--training_patient_id
1
--load_intermediate_data
--num_epoch
200
--num_iter
1000
--architecture_summary
--data_root
"D:\Data\example_training_data_root\example_training_data_root"
--log_root
"D:\Data\example_training_data_root\Train"
--precompute_root
"D:\Data\example_training_data_root\Train\precompute"
--descriptor_model_path
"D:\Data\trained_models\descriptor\checkpoint_model_epoch_48_0.5595721672900287_0.6460666084922773_0.7442676028192171.pt"
--load_trained_model
--trained_model_path
"D:\Data\example_training_data_root\Train\depth_train_6_24_22_42\checkpoint_model_epoch_12_3.6285473743526744_0.25684059195569486_0.2541229816672874_3.117583790192461_0.0.pt"


# Fine-tuning
--adjacent_range
5
30
--image_downsampling
4.0
--network_downsampling
64
--input_size
256
320
--batch_size
1
--num_workers
1
--slp_weight
0.05
--dcl_weight
0.5
--sfl_weight
10.0
--dl_weight
0.05
--lr_range
1.0e-4
1.0e-3
--inlier_percentage
0.9
--display_interval
20
--visible_interval
5
--save_interval
1
--training_patient_id
1
--load_intermediate_data
--num_epoch
200
--num_iter
1000
--architecture_summary
--data_root
"D:\Data\example_training_data_root\example_training_data_root"
--log_root
"D:\Data\example_training_data_root\Train"
--precompute_root
"D:\Data\example_training_data_root\Train\precompute"
--descriptor_model_path
"D:\Data\trained_models\descriptor\checkpoint_model_epoch_48_0.5595721672900287_0.6460666084922773_0.7442676028192171.pt"
--load_trained_model
--trained_model_path
"D:\Data\example_training_data_root\Train\depth_train_6_24_23_6\checkpoint_model_epoch_42_1.9672575944990602_-0.09981718826232348_-0.572694770307366_2.6397695492102398_0.0.pt"

# visibility interval change to 1
--adjacent_range
5
30
--image_downsampling
4.0
--network_downsampling
64
--input_size
256
320
--batch_size
1
--num_workers
1
--slp_weight
0.05
--dcl_weight
0.5
--sfl_weight
10.0
--dl_weight
0.05
--lr_range
1.0e-4
1.0e-3
--inlier_percentage
0.9
--display_interval
20
--visible_interval
1
--save_interval
1
--training_patient_id
1
--load_intermediate_data
--num_epoch
200
--num_iter
1000
--architecture_summary
--data_root
"D:\Data\example_training_data_root\example_training_data_root"
--log_root
"D:\Data\example_training_data_root\Train"
--precompute_root
"D:\Data\example_training_data_root\Train\precompute"
--descriptor_model_path
"D:\Data\trained_models\descriptor\checkpoint_model_epoch_48_0.5595721672900287_0.6460666084922773_0.7442676028192171.pt"
--load_trained_model
--trained_model_path
"D:\Data\example_training_data_root\Train\depth_train_6_25_13_16\checkpoint_model_epoch_43_3.289899355471135_-0.11413562958859258_-0.7448422023653978_3.6561081040501566_0.49276908864080904.pt"